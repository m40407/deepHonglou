{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import io\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload_data = False\n",
    "\n",
    "if reload_data:\n",
    "    corpus_raw = open('./honglou80.txt','r').read()\n",
    "\n",
    "    print(\"Corpus is {} characters long\".format(len(corpus_raw)))\n",
    "\n",
    "    words = jieba.lcut(corpus_raw,cut_all=False,HMM=True)\n",
    "\n",
    "    def create_lookup_tables(text):\n",
    "        \"\"\"\n",
    "        Create lookup tables for vocab\n",
    "        :param text: The GOT text split into words\n",
    "        :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "        \"\"\"\n",
    "        vocab = set(text)\n",
    "        int_to_vocab = {key: word for key, word in enumerate(vocab)}\n",
    "        vocab_to_int = {word: key for key, word in enumerate(vocab)}\n",
    "        return vocab_to_int, int_to_vocab\n",
    "\n",
    "    vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
    "    corpus_int = [vocab_to_int[word] for word in words]\n",
    "    pickle.dump((corpus_int, vocab_to_int, int_to_vocab), open('preprocess.p', 'wb'))\n",
    "else:\n",
    "    corpus_int,vocab_to_int,int_to_vocab = pickle.load(open('preprocess.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Network\n",
    "### Batch the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target data\n",
    "    :param int_text: text with words replaced by their ids\n",
    "    :param batch_size: the size that each batch of data should be\n",
    "    :param seq_length: the length of each sequence\n",
    "    :return: batches of data as a numpy array\n",
    "    \"\"\"\n",
    "    words_per_batch = batch_size * seq_length\n",
    "    num_batches = len(int_text)//words_per_batch\n",
    "    int_text = int_text[:num_batches*words_per_batch]\n",
    "    y = np.array(int_text[1:] + [int_text[0]])\n",
    "    x = np.array(int_text)\n",
    "    \n",
    "    x_batches = np.split(x.reshape(batch_size, -1), num_batches, axis=1)\n",
    "    y_batches = np.split(y.reshape(batch_size, -1), num_batches, axis=1)\n",
    "    \n",
    "    batch_data = list(zip(x_batches, y_batches))\n",
    "    \n",
    "    return np.array(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "rnn_size = 1024\n",
    "num_layers = 3\n",
    "keep_prob = 0.7\n",
    "embed_dim = 1024\n",
    "seq_length = 50\n",
    "learning_rate = 0.001\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():    \n",
    "    \n",
    "    # Initialize input placeholders\n",
    "    input_text = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    # Calculate text attributes\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text_shape = tf.shape(input_text)\n",
    "    \n",
    "    def lstm_cell():\n",
    "        # Build the RNN cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_size)\n",
    "        drop_cell = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop_cell\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(num_layers)])\n",
    "    \n",
    "    # Set the initial state\n",
    "    initial_state = cell.zero_state(input_text_shape[0], tf.float32)\n",
    "    initial_state = tf.identity(initial_state, name='initial_state')\n",
    "    \n",
    "    # Create word embedding as input to RNN\n",
    "    embed = tf.contrib.layers.embed_sequence(input_text, vocab_size, embed_dim)\n",
    "    \n",
    "    # Build RNN\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, name='final_state')\n",
    "    \n",
    "    # Take RNN output and make logits\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, vocab_size, activation_fn=None)\n",
    "    \n",
    "    # Calculate the probability of generating each word\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "    \n",
    "    # Define loss function\n",
    "    cost = tf.contrib.seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_text_shape[0], input_text_shape[1]]),\n",
    "        name='cost'\n",
    "    )\n",
    "    \n",
    "    # Learning rate optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # Gradient clipping to avoid exploding gradients\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients,name='train_op')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch   63/63   train_loss = 7.073   time_elapsed = 43.811   time_remaining = 21861\n",
      "Model Trained and Saved\n",
      "Epoch   2 Batch   63/63   train_loss = 6.984   time_elapsed = 88.070   time_remaining = 21929\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pickle.dump((seq_length, save_dir), open('params.p', 'wb'))\n",
    "batches = get_batches(corpus_int, batch_size, seq_length)\n",
    "num_batches = len(batches)\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "        \n",
    "        for batch_index, (x, y) in enumerate(batches):\n",
    "            feed_dict = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate\n",
    "            }\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed_dict)\n",
    "            \n",
    "        with open('cost.txt','a') as f:\n",
    "            f.write('%.3f\\n'%train_loss)\n",
    "            \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}   time_elapsed = {:.3f}   time_remaining = {:.0f}'.format(\n",
    "            epoch + 1,\n",
    "            batch_index + 1,\n",
    "            len(batches),\n",
    "            train_loss,\n",
    "            time_elapsed,\n",
    "            ((num_batches * num_epochs)/((epoch + 1) * (batch_index + 1))) * time_elapsed - time_elapsed))\n",
    "\n",
    "        # save model every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.save(sess, save_dir)\n",
    "            \n",
    "            print('Model Trained and Saved')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"targets:0\", shape=(?, ?), dtype=int32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/shareApp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    929\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m--> 930\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m    931\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shareApp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shareApp/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2492\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2493\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2494\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"targets:0\", shape=(?, ?), dtype=int32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-399c986eb14d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             }\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shareApp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shareApp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    931\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m--> 933\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"targets:0\", shape=(?, ?), dtype=int32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "# reload graph and continue training\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load the saved model\n",
    "    loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
    "    loader.restore(sess, save_dir)\n",
    "    \n",
    "    # Get tensors from loaded graph\n",
    "    input_text = loaded_graph.get_tensor_by_name('input:0')\n",
    "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    train_op = loaded_graph.get_operation_by_name('train_op:0')\n",
    "    cost = loaded_graph.get_tensor_by_name('cost:0')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "        \n",
    "        for batch_index, (x, y) in enumerate(batches):\n",
    "            feed_dict = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate\n",
    "            }\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed_dict)\n",
    "            \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}   time_elapsed = {:.3f}   time_remaining = {:.0f}'.format(\n",
    "            epoch + 1,\n",
    "            batch_index + 1,\n",
    "            len(batches),\n",
    "            train_loss,\n",
    "            time_elapsed,\n",
    "            ((num_batches * num_epochs)/((epoch + 1) * (batch_index + 1))) * time_elapsed - time_elapsed))\n",
    "\n",
    "        # save model every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.save(sess, save_dir)\n",
    "            print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GOT Text\n",
    "### Pick a Random Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word with some randomness\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    return np.random.choice(list(int_to_vocab.values()), 1, p=probabilities)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Graph and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "你们东府里除了那两个石头狮子干净，只怕猫儿狗儿都不干净，我就有你说的；若怕外头如此，我竟不说了。”一面说，一面往外都写。迎春便坐在山石上，说道：“宝二爷去了，我想不到要见你的踢老太太看，也有扇酒，怎么不给我去。”宝玉见说的便送到两个里来，只见兴儿出来时，又有话喝，忽见平儿回说道：“二奶奶打发他到这个来的，自没有借他的话。你是说有人不好。”\n",
      "周瑞家的道：“姑娘说去。”说着道：“老太太竟了，隔着许多眼，他们又老上说去；他带的小丫头们。我没两个不解，却连他们又丢过奶奶，然后不遂心，小拐你两件若干地方，不拿奶奶手里去。再在外头前，只说是一个：‘累得姑娘们跟了他几个人，他就不肯照管你取笑儿了。”黛玉忙笑道：“既有，当日方才太太见了他姐妹，忙说我们不错，若说‘自古来许多。”宝玉道：“正是的怎么我子呢？”\n",
      "又道：“小厮们自然这么高兴了，不敢足有一句，这也不是得他的。”凤姐儿道：“我说你再叫他在里头，刚才奶奶已经回了这个：事情怎么了，这样事情，二爷再一书房出来，昨日破了银子给我，也没有‘宝玉’字。”\n",
      "李纨又笑道：“这是个姑娘跟前才是。——只因你自己一处再去，怎么也不照看得好罢？”宝玉道：“这是什么香？”\n",
      "一语未了，只见探春道：“有我罢了，咱们我才服他！”宝玉心中急的名，凤姐也来至榻上，去找宝玉，又不好时，不过是催他说呢。此时自是醉了，再只说笑了。\n",
      "谁知凤姐命他过来，忽见些话的身子都觉，只说无处可，我只同他闹的你们和我琏宝玉的。”贾环听了，便将他手中伏侍“一年、一群人的时候儿，莺儿岂不认得些呢？\n",
      "这里贾瑞言到宝玉坐了，只得写下。黛玉一面哭，一面又问：“你想什么利害？我才和这里，这是炕上，你倒来搜了？”一面说，一面拉着王善保书房来找王夫人。麝月只问：“你这么谁？怎么就进了茶？就另来了！”宝玉道：“我要说你里头，你说妹妹一句话，我就回来了。”说着，“宝玉又该做什么神呢？”迎春道：“姐姐今儿怎么离了藕香榭？”贾芸笑道：“你瞧他这几日没家给他来？”宝玉因问：“在家里做什么呢？”宝玉在厅上便向里道：“屋里是什么日子？”地下的一个早已不知不看时，独却是《风流硝，内有对人起完，一齐插上完了半夜。\n",
      "忽见众人在里间屋里房中，只见两三个两处大一个一看，正是：“好一个”，只要手早来才要让。\n",
      "两个三姐儿唤他的肉，倒是邢夫人跟前，也就不和贾琏说笑。只有他婆子在后屋里，谁知宝二爷给他们捶腿，你们才好说话，只说他说的，好说：谁等你要着去，叫他回来闹去。”宝玉道：“就剩了你我了，看见两个人，就在上房园子里在里头闹，再睡了？等他们到了跟前，我就写着。”\n",
      "平儿道：“我带了你主子去，看他少了更好茶，我还和我们无干。若有了事来，想来都有个好东西，你吃的不了。”一面说，一面又要伤心。贾政道：“不用问，他是留起来，又知道告诉了我。”宝玉冷笑道：“除了什么‘爷’‘满床》一首极好，虽说为‘一先’的事，还可忌讳？”林之孝家的道：“我说你是‘金刚’‘兰’，亦或是过于日。\n",
      "他是下雨，不过‘假中，这却可。”那小丫头进来，说：“我的丫头也是你的？”迎春听了，便不敢兼，黛玉又要听宝玉，只剩了一后\n"
     ]
    }
   ],
   "source": [
    "gen_length = 1000\n",
    "prime_words = '你们东府里除了那两个石头狮子干净，只怕猫儿狗儿都不干净'\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load the saved model\n",
    "    loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
    "    loader.restore(sess, save_dir)\n",
    "    \n",
    "    # Get tensors from loaded graph\n",
    "    input_text = loaded_graph.get_tensor_by_name('input:0')\n",
    "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    \n",
    "    # Sentences generation setup\n",
    "    gen_sentences = jieba.lcut(prime_words)\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1 for word in gen_sentences]])})\n",
    "    \n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "        \n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "\n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "        \n",
    "    # Remove tokens\n",
    "    chapter_text = ''.join(gen_sentences).replace('||','\\r\\n')\n",
    "        \n",
    "print(chapter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "刚进了门，便放声大哭起来。黛玉正在梳洗才毕，见宝玉这个光景，倒吓了一跳，问：“是怎么了？和谁怄了气了？”\n",
      "凤姐道：“他拿的我来了。”宝玉道：“你到底都明白，和二姑娘不带来，又不用听见。让他娘的女儿想？因我亲自知道。”尤氏又要家常说，只因王夫人道：“你不要你，又是个多心的一个，连大姨娘不说，做多给我妈，你又不用说说就是了。”贾母听说，只管站起来，只在“府儿了，两边也不知“宝玉实在好的。那小丫头想了，好主意，所以他却不提，忙又问道：“你倒是个事情？”\n",
      "宝玉细说话，只得忍了一张房中，念道：“大妹妹和岫老舅舅无人，便自己吃着出去传了，这里宝钗往那里去了？别说姑娘不放心，只见凤姐、太太、太太一齐都去。到姐儿床上，三姐儿已过了工夫，我们烦他知道：“你们好生去了，一日回来请安。就是他们，我不跑起老太太和人必不上房。”因纨、迎春、探春、彩云等都捧着瞧，也笑向李纨道：“你奶奶也遇见我们两个去了！那两句话，姑娘都不敢，我也是拾着，你们得罪了这个儿，且也有‘男、里头’，难道就是你的‘贝鸡’，自然你起一半呢！”宝玉听了，忙推众人道：“老太太等我替我躲去了。”说着便走。凤姐自不自在，只得回房找他。兴儿也念在女儿，急的是个玉，见他拿了一爱去，亲自拿毕，忽见宝玉笑道：“我只那里收你的手？说出来，只到给那边去。”王夫人说：“我又不知他是谁。”宝玉忙收了茶，二人说：“你说了，今儿可又不是了。”鸳鸯道：“你难道这个是这个姑娘？”\n",
      "一时薛姨妈又说道：“你问他做什么？”宝玉又笑道：“你若忘了，我细细的告诉了，又瞧：“好生走。”说着，“嗤”的一声说：“你去瞧我说你看看，我就知道。”一语未了，只见贾政进来，凤姐往下屋里去瞧黛玉。周瑞家的说：“姑娘在这里想，要和你们一处吃好什么没有？”宝玉道：“就说得些不用利害？”凤姐儿笑道：“方才两个症雪，你可知道是我替三一个。”黛玉冷笑道：“你会做过的是什么？”刘老老先叫：“瞎了眼的，我又要这么大，只说这么完了；饶了我罢。”说毕，叫他接过，也想起来回了，因说：“我知道好了，你要‘一处一般，‘姐姐’我就题着，谁不知道呢？我怨不得你要错，只在这里回来呢。”湘云道：“你放心，我这会子再多心，都一日急了我们，前儿告诉我和你孙子好话，别的彼此感动了个梦，细来，就有趣儿。”贾母道：“你又提是了，只是回了你。”要哭道：“这打呢：来的，我只拣你来了。我是笑话不成！”袭人听了此话，问道：“你也是有姑娘的衣裳，说没得话？”宝玉听了，便拉那丫头：“取了来？”宝玉笑道：“你仍旧在家里：我是那里了？”宝玉道：“那里不是了？我不知道别人，须是这么更吵呢！”宝玉道：“撕他就疼我！\n",
      "——宁可哭了！\n",
      "他是宝玉，竟是一件我要送来的，老太太自然是和人想呢。”黛玉走的半天，说：“巧也不出门，等主子来！”迎春冷笑道：“什么‘院里’老婆子极妙。”黛玉道：“且再看。”袭人便道：“这是人说的这些：里头是个‘四儿’字，必是一点儿不知道罢了。”宝玉道：“宝‘夫妻’的韵，怎么过呢！你不拣，多谢你做？”\n",
      "说到这婆子出去了。宝钗手里来了这话，又忙说：“不是什么，何必说‘爱’的事，前儿竟知道了。我刚才还不知道：“是你素日头年纪珠吃了。我又往我\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"刚进了门，便放声大哭起来。黛玉正在梳洗才毕，见宝玉这个光景，倒吓了一跳，问：“是怎么了？和谁怄了气了？”\n",
    "凤姐道：“他拿的我来了。”宝玉道：“你到底都明白，和二姑娘不带来，又不用听见。让他娘的女儿想？因我亲自知道。”尤氏又要家常说，只因王夫人道：“你不要你，又是个多心的一个，连大姨娘不说，做多给我妈，你又不用说说就是了。”贾母听说，只管站起来，只在“府儿了，两边也不知“宝玉实在好的。那小丫头想了，好主意，所以他却不提，忙又问道：“你倒是个事情？”\n",
    "宝玉细说话，只得忍了一张房中，念道：“大妹妹和岫老舅舅无人，便自己吃着出去传了，这里宝钗往那里去了？别说姑娘不放心，只见凤姐、太太、太太一齐都去。到姐儿床上，三姐儿已过了工夫，我们烦他知道：“你们好生去了，一日回来请安。就是他们，我不跑起老太太和人必不上房。”因纨、迎春、探春、彩云等都捧着瞧，也笑向李纨道：“你奶奶也遇见我们两个去了！那两句话，姑娘都不敢，我也是拾着，你们得罪了这个儿，且也有‘男、里头’，难道就是你的‘贝鸡’，自然你起一半呢！”宝玉听了，忙推众人道：“老太太等我替我躲去了。”说着便走。凤姐自不自在，只得回房找他。兴儿也念在女儿，急的是个玉，见他拿了一爱去，亲自拿毕，忽见宝玉笑道：“我只那里收你的手？说出来，只到给那边去。”王夫人说：“我又不知他是谁。”宝玉忙收了茶，二人说：“你说了，今儿可又不是了。”鸳鸯道：“你难道这个是这个姑娘？”\n",
    "一时薛姨妈又说道：“你问他做什么？”宝玉又笑道：“你若忘了，我细细的告诉了，又瞧：“好生走。”说着，“嗤”的一声说：“你去瞧我说你看看，我就知道。”一语未了，只见贾政进来，凤姐往下屋里去瞧黛玉。周瑞家的说：“姑娘在这里想，要和你们一处吃好什么没有？”宝玉道：“就说得些不用利害？”凤姐儿笑道：“方才两个症雪，你可知道是我替三一个。”黛玉冷笑道：“你会做过的是什么？”刘老老先叫：“瞎了眼的，我又要这么大，只说这么完了；饶了我罢。”说毕，叫他接过，也想起来回了，因说：“我知道好了，你要‘一处一般，‘姐姐’我就题着，谁不知道呢？我怨不得你要错，只在这里回来呢。”湘云道：“你放心，我这会子再多心，都一日急了我们，前儿告诉我和你孙子好话，别的彼此感动了个梦，细来，就有趣儿。”贾母道：“你又提是了，只是回了你。”要哭道：“这打呢：来的，我只拣你来了。我是笑话不成！”袭人听了此话，问道：“你也是有姑娘的衣裳，说没得话？”宝玉听了，便拉那丫头：“取了来？”宝玉笑道：“你仍旧在家里：我是那里了？”宝玉道：“那里不是了？我不知道别人，须是这么更吵呢！”宝玉道：“撕他就疼我！\n",
    "——宁可哭了！\n",
    "他是宝玉，竟是一件我要送来的，老太太自然是和人想呢。”黛玉走的半天，说：“巧也不出门，等主子来！”迎春冷笑道：“什么‘院里’老婆子极妙。”黛玉道：“且再看。”袭人便道：“这是人说的这些：里头是个‘四儿’字，必是一点儿不知道罢了。”宝玉道：“宝‘夫妻’的韵，怎么过呢！你不拣，多谢你做？”\n",
    "说到这婆子出去了。宝钗手里来了这话，又忙说：“不是什么，何必说‘爱’的事，前儿竟知道了。我刚才还不知道：“是你素日头年纪珠吃了。我又往我\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['第八十一回']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut(prime_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a Chapter\n",
    "### Cleanup Data a Bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chapter_text = ' '.join(gen_sentences)\n",
    "for key, token in token_dict.items():\n",
    "    chapter_text = chapter_text.replace(' ' + token.lower(), key)\n",
    "chapter_text = chapter_text.replace('\\n ', '\\n')\n",
    "chapter_text = chapter_text.replace('( ', '(')\n",
    "chapter_text = chapter_text.replace(' ”', '”')\n",
    "\n",
    "capitalize_words = ['lannister', 'stark', 'lord', 'ser', 'tyrion', 'jon', 'john snow', 'daenerys', 'targaryen', 'cersei', 'jaime', 'arya', 'sansa', 'bran', 'rikkon', 'joffrey', \n",
    "                    'khal', 'drogo', 'gregor', 'clegane', 'kings landing', 'winterfell', 'the mountain', 'the hound', 'ramsay', 'bolton', 'melisandre', 'shae', 'tyrell',\n",
    "                   'margaery', 'sandor', 'hodor', 'ygritte', 'brienne', 'tarth', 'petyr', 'baelish', 'eddard', 'greyjoy', 'theon', 'gendry', 'baratheon', 'baraTheon',\n",
    "                   'varys', 'stannis', 'bronn', 'jorah', 'mormont', 'martell', 'oberyn', 'catelyn', 'robb', 'loras', 'missandei', 'tommen', 'robert', 'lady', 'donella', 'redwyne'\n",
    "                   'myrcella', 'samwell', 'tarly', 'grey worm', 'podrick', 'osha', 'davos', 'seaworth', 'jared', 'jeyne poole', 'rickard', 'yoren', 'meryn', 'trant', 'king', 'queen',\n",
    "                   'aemon']\n",
    "\n",
    "for word in capitalize_words:\n",
    "    chapter_text = chapter_text.replace(word, word.lower().title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "version_dir = './generated-book-v1'\n",
    "if not os.path.exists(version_dir):\n",
    "    os.makedirs(version_dir)\n",
    "\n",
    "num_chapters = len([name for name in os.listdir(version_dir) if os.path.isfile(os.path.join(version_dir, name))])\n",
    "next_chapter = version_dir + '/chapter-' + str(num_chapters + 1) + '.md'\n",
    "with open(next_chapter, \"w\") as text_file:\n",
    "    text_file.write(chapter_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
